# <p align=center>`awesome-generation`</p>
A collection of resources on generation. Maintained by [IIGroup](https://sites.google.com/view/iigroup-thu/home?authuser=0).

<!-- ## Contributing

If you think I have missed out on something (or) have any suggestions (papers, implementations and other resources), feel free to [pull a request](https://github.com/xiaweihao/awesome-image-translation/pulls). Feedback and contributions are welcome!

markdown format:
``` markdown
**Here is the Paper Name.**<br>
*[Author 1](homepage), Author 2, and Author 3.*<br>
Conference or Journal Year. [[PDF](link)] [[Project](link)] [[Github](link)] [[Video](link)] [[Data](link)]
``` -->

<details><summary>Table of Contents</summary><p>

- [GAN Inversion](#gan-inversion)
- [3D-GAN](#3d-gan)
</p></details><p></p>


## GAN Inversion

**HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing.**<br>
*Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, Amit H. Bermano.*<br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2111.15666)]

## 3D-GAN

**Pix2NeRF: Unsupervised Conditional Ï€-GAN for Single Image to Neural Radiance Fields Translation.**<br>
*Shengqu Cai, Anton Obukhov, Dengxin Dai, Luc Van Gool.*<br>
CVPR 2022. [[PDF](https://arxiv.org/abs/2202.13162)]

